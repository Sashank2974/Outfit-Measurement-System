version: '3.8'

services:
  # PostgreSQL Database
  postgres:
    image: postgres:15-alpine
    container_name: ai_body_measurement_postgres
    environment:
      POSTGRES_DB: body_measurement_db
      POSTGRES_USER: admin
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-changeme123}
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./database/schema.sql:/docker-entrypoint-initdb.d/schema.sql
    networks:
      - app_network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U admin -d body_measurement_db"]
      interval: 10s
      timeout: 5s
      retries: 5

  # MongoDB for logs and metadata
  mongodb:
    image: mongo:7-jammy
    container_name: ai_body_measurement_mongodb
    environment:
      MONGO_INITDB_ROOT_USERNAME: admin
      MONGO_INITDB_ROOT_PASSWORD: ${MONGO_PASSWORD:-changeme123}
    ports:
      - "27017:27017"
    volumes:
      - mongodb_data:/data/db
    networks:
      - app_network
    healthcheck:
      test: echo 'db.runCommand("ping").ok' | mongosh localhost:27017/test --quiet
      interval: 10s
      timeout: 5s
      retries: 5

  # Redis for caching
  redis:
    image: redis:7-alpine
    container_name: ai_body_measurement_redis
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    networks:
      - app_network
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    command: redis-server --appendonly yes

  # Backend API
  backend:
    build:
      context: ./backend
      dockerfile: ../deployment/Dockerfile.backend
    container_name: ai_body_measurement_backend
    environment:
      - DATABASE_URL=postgresql://admin:${POSTGRES_PASSWORD:-changeme123}@postgres:5432/body_measurement_db
      - MONGODB_URL=mongodb://admin:${MONGO_PASSWORD:-changeme123}@mongodb:27017
      - REDIS_URL=redis://redis:6379
      - SECRET_KEY=${SECRET_KEY:-your-secret-key-change-in-production}
      - AI_MODEL_URL=http://ai_model:5000
      - ENVIRONMENT=development
    ports:
      - "8000:8000"
    volumes:
      - ./backend:/app
      - uploaded_images:/app/uploads
    depends_on:
      postgres:
        condition: service_healthy
      mongodb:
        condition: service_healthy
      redis:
        condition: service_healthy
    networks:
      - app_network
    command: uvicorn app:app --host 0.0.0.0 --port 8000 --reload

  # AI Model Server
  ai_model:
    build:
      context: ./ai_model
      dockerfile: ../deployment/Dockerfile.ai
    container_name: ai_body_measurement_ai
    environment:
      - MODEL_PATH=/models
      - REDIS_URL=redis://redis:6379
    ports:
      - "5000:5000"
    volumes:
      - ./ai_model:/app
      - model_data:/models
    depends_on:
      - redis
    networks:
      - app_network
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    command: python serve_model.py

  # Frontend
  frontend:
    build:
      context: ./frontend
      dockerfile: ../deployment/Dockerfile.frontend
    container_name: ai_body_measurement_frontend
    environment:
      - NEXT_PUBLIC_API_URL=http://localhost:8000
      - NODE_ENV=development
    ports:
      - "3000:3000"
    volumes:
      - ./frontend:/app
      - /app/node_modules
      - /app/.next
    depends_on:
      - backend
    networks:
      - app_network
    command: npm run dev

  # Celery Worker (for async tasks)
  celery_worker:
    build:
      context: ./backend
      dockerfile: ../deployment/Dockerfile.backend
    container_name: ai_body_measurement_celery
    environment:
      - DATABASE_URL=postgresql://admin:${POSTGRES_PASSWORD:-changeme123}@postgres:5432/body_measurement_db
      - MONGODB_URL=mongodb://admin:${MONGO_PASSWORD:-changeme123}@mongodb:27017
      - REDIS_URL=redis://redis:6379
      - AI_MODEL_URL=http://ai_model:5000
    volumes:
      - ./backend:/app
    depends_on:
      - postgres
      - mongodb
      - redis
      - ai_model
    networks:
      - app_network
    command: celery -A tasks worker --loglevel=info

  # Flower (Celery monitoring)
  flower:
    build:
      context: ./backend
      dockerfile: ../deployment/Dockerfile.backend
    container_name: ai_body_measurement_flower
    environment:
      - REDIS_URL=redis://redis:6379
    ports:
      - "5555:5555"
    depends_on:
      - redis
      - celery_worker
    networks:
      - app_network
    command: celery -A tasks flower --port=5555

  # Nginx (Reverse Proxy)
  nginx:
    image: nginx:alpine
    container_name: ai_body_measurement_nginx
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./deployment/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./deployment/ssl:/etc/nginx/ssl:ro
    depends_on:
      - frontend
      - backend
    networks:
      - app_network

networks:
  app_network:
    driver: bridge

volumes:
  postgres_data:
  mongodb_data:
  redis_data:
  model_data:
  uploaded_images:
